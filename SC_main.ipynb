{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import h5py\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_FILE_PATH = r\"\"\n",
    "EXTRACTION_PATH = r\"\"\n",
    "OUTPUT_PATH = r\"\"\n",
    "SELECTED_CLASSES = [\"pizza\", \"sushi\", \"ice_cream\", \"fried_rice\"]\n",
    "IMAGES_PER_CLASS = 50\n",
    "IMAGE_SIZE = (224, 224)\n",
    "N_CLUSTERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, extraction_path):\n",
    "    if not os.path.exists(extraction_path):\n",
    "        os.makedirs(extraction_path)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extraction_path)\n",
    "    print(f\"Files extracted to {extraction_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])  # حذف لایه‌ی Fully Connected\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to read image: {image_path}\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image).squeeze().cpu().numpy()\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_h5_files(extraction_path):\n",
    "    h5_files = []\n",
    "    for root, dirs, files in os.walk(extraction_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".h5\"):\n",
    "                h5_files.append(os.path.join(root, file))\n",
    "    return h5_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5_file(h5_file_path):\n",
    "    with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "        print(f\"Reading {h5_file_path}:\")\n",
    "        metadata = {}\n",
    "        for key in h5_file.keys():\n",
    "            metadata[key] = h5_file[key][:]\n",
    "        return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset():\n",
    "    \n",
    "    for class_name in SELECTED_CLASSES:\n",
    "        class_path = os.path.join(EXTRACTION_PATH, \"images\", class_name)\n",
    "        output_class_path = os.path.join(OUTPUT_PATH, \"images\", class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "        \n",
    "        features = []\n",
    "        image_paths = []\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                feat = extract_features(img_path)\n",
    "                features.append(feat)\n",
    "                image_paths.append(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "        features = np.array(features)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(features)\n",
    "\n",
    "        selected_images = []\n",
    "        for cluster_id in range(N_CLUSTERS):\n",
    "            cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
    "            np.random.shuffle(cluster_indices)\n",
    "            selected_indices = cluster_indices[:IMAGES_PER_CLASS // N_CLUSTERS]\n",
    "            selected_images.extend([image_paths[i] for i in selected_indices])\n",
    "\n",
    "        for img_path in selected_images:\n",
    "            shutil.copy(img_path, output_class_path)\n",
    "\n",
    "        print(f\"Class {class_name}: {len(selected_images)} images selected.\")\n",
    "        \n",
    "    meta_path = os.path.join(EXTRACTION_PATH, \"meta\")\n",
    "    output_meta_path = os.path.join(OUTPUT_PATH, \"meta\")\n",
    "    if os.path.exists(meta_path):\n",
    "        shutil.copytree(meta_path, output_meta_path, dirs_exist_ok=True)\n",
    "        print(f\"Metadata copied to {output_meta_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to D:\\AI projects\\calorie_counter\\food101\n",
      "Reading D:\\AI projects\\calorie_counter\\food101\\food_c101_n1000_r384x384x3.h5:\n",
      "Example metadata: ['category', 'category_names', 'images']\n",
      "Class pizza: 50 images selected.\n",
      "Class sushi: 50 images selected.\n",
      "Class ice_cream: 50 images selected.\n",
      "Class fried_rice: 50 images selected.\n",
      "Metadata copied to D:\\AI projects\\calorie_counter\\food101-subset\\meta\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    extract_zip(ZIP_FILE_PATH, EXTRACTION_PATH)\n",
    "\n",
    "    h5_files = list_h5_files(EXTRACTION_PATH)\n",
    "    if h5_files:\n",
    "        metadata = read_h5_file(h5_files[0])\n",
    "        print(f\"Example metadata: {list(metadata.keys())}\")\n",
    "\n",
    "    create_subset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
